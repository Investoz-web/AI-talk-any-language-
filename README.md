# Realtime-voice-translate
Building AI course project.

## Summary
An AI system that enables real-time communication between people who speak different languages, where each person can speak their native language and still be understood instantly.
The goal is to create communication that feels as natural and human as possible, without language barriers getting in the way.

## Problems it will solve
Language barriers are a major global problem that limit communication between people. Although translation apps exist today, they are often slow, unnatural, limited to text or monotonous and robotic speech.
They rarely capture tone of voice, emotions, and personality, which are central to human communication. My idea addresses this by combining translation with voice-preserving technology, making conversations more personal and easier to understand.

## How common is the problem?
Millions of people encounter language barriers on a daily basis.
The problem is very common and affects:
- Travelers and tourists
- International companies
- Migrants and newly arrived immigrants
- Healthcare workers, teachers, and public authorities

## Personal Motivation
My personal motivation comes from seeing how language often becomes a barrier to inclusion and understanding. I want to use AI to make communication more equal, where language does not determine who gets to speak or be understood.

## Why is this topic important or interesting?
Language is central to cooperation, integration, and human relationships. Reducing language barriers can:
- Facilitate global collaboration
- Improve integration
- Create better understanding between cultures
This makes the topic both socially important and technically interesting.

# Data and AI Techniques
## Data Sources
The project depends on several types of data:
- Speech data for speech recognition
- Parallel language data for translation
- Voice recordings from users to recreate their voice
Examples of open data sources include:
- Common Voice (open speech data)
- OpenSubtitles (translated text)
- LibriSpeech
## AI Techniques
The following AI techniques are used:
- Speech-to-Text (speech recognition)
- Neural Machine Translation
- Text-to-Speech (speech synthesis)
- Voice Cloning / voice synthesis
- Low-latency real-time streaming
The technology is based on modern neural networks, such as transformer models.

# How Is the Solution Used?
The solution can be used in:
- Conversations between two people
- Digital meetings
- Customer support
- Travel and tourism
- Education and integration

# Who Uses It?
- Private individuals
- Companies
- Public institutions
- Migrants and international students

# Who Is Affected?
Everyone who is currently limited by language barriers would be positively affected, both socially and economically.

# Challenges and Limitations
The project does not solve all problems:
- Dialects and slang can be difficult to interpret
- Humor and cultural expressions may be lost
- Latency must be kept extremely low
- There are ethical risks related to voice misuse
Therefore, clear security measures and user consent are required.

# What Happens Next?
The project could be further developed by:
- Supporting more languages and dialects
- Integrating with headphones or AR glasses
 -Being used in VR and gaming environments
- Adapting to the userâ€™s personal speaking style
In the long term, this could become a standard tool for global communication.
